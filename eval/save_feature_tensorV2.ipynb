{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package, module setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from torch import cuda\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from mymodels.resnet_base_network import ResNet18\n",
    "from mydata.imageloader import MyDataset, psnrDataUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_transforms = torchvision.transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "config = yaml.load(open(\"../config/config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "# device = 'cpu'\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Training with: {device}\")\n",
    "if device=='cuda':\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-data, Test-data\n",
    "- shuffle the train data\n",
    "- dataset\n",
    "- dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_list = []\n",
    "file_path = \"/home/hong/dir1/PyTorch-BYOL/user_1.txt\"\n",
    "\n",
    "f = open(file_path, 'r')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    listed = line.split(\" \")\n",
    "    tmp_unit = psnrDataUnit(listed[0], listed[1], listed[2], listed[3])\n",
    "    pair_list.append(tmp_unit)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/mnt/URP_DS/HR' # without last slash\n",
    "test_data_path = '/mnt/URP_DS/HR'  #without last slash\n",
    "\n",
    "# train_data_path = '/mnt/URP_DS/HR' # without last slash\n",
    "# test_data_path = '/mnt/URP_DS/HR'  #without last slash\n",
    "\n",
    "img1_idx = 0\n",
    "\n",
    "train_imgs_psnr_list = []\n",
    "for p_unit in pair_list:\n",
    "    # train_imgs_psnr_list.append((train_data_path+'/'+p_unit.getimg1()+'.png', train_data_path+'/'+p_unit.getimg2()+'.png', p_unit.getsrsum()))\n",
    "    train_imgs_psnr_list.append((train_data_path+'/'+p_unit.getimg1(), train_data_path+'/'+p_unit.getimg2(), p_unit.getsrsum()))\n",
    "\n",
    "test_imgs_psnr_list = []\n",
    "for p_unit in pair_list:\n",
    "    # test_imgs_psnr_list.append((test_data_path+'/'+p_unit.getimg1()+'.png', test_data_path+'/'+p_unit.getimg2()+'.png', p_unit.getsrsum()))\n",
    "    test_imgs_psnr_list.append((test_data_path+'/'+p_unit.getimg1(), test_data_path+'/'+p_unit.getimg2(), p_unit.getsrsum()))\n",
    "\n",
    "\n",
    "# split train valid from train paths (80,20), (1, 99) -> just for convention\n",
    "set_ratio1 = 1\n",
    "set_ratio2 = 1-set_ratio1\n",
    "\n",
    "if set_ratio1<1:\n",
    "    train_imgs_psnr_list, train2_imgs_psnr_list = train_imgs_psnr_list[:int(set_ratio1*len(train_imgs_psnr_list))], train_imgs_psnr_list[int(set_ratio2*len(train_imgs_psnr_list)):]\n",
    "    test_imgs_psnr_list, test2_imgs_psnr_list = test_imgs_psnr_list[:int(set_ratio1*len(test_imgs_psnr_list))], test_imgs_psnr_list[int(set_ratio2*len(test_imgs_psnr_list)):]\n",
    "\n",
    "# shuffle the pairs for training\n",
    "import random\n",
    "random.shuffle(train_imgs_psnr_list)\n",
    "\n",
    "print('test_image_path example: ', test_imgs_psnr_list[img1_idx])\n",
    "print('train_image_path example: ', train_imgs_psnr_list[img1_idx])\n",
    "print(len(train_imgs_psnr_list), len(test_imgs_psnr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_imgs_psnr_list, transform=data_transforms)\n",
    "test_dataset = MyDataset(test_imgs_psnr_list, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input shape:\", train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          num_workers=0, drop_last=False, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                          num_workers=0, drop_last=False, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder loading\n",
    "load encoder for both images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ResNet18(**config['network'])\n",
    "output_feature_dim = encoder.projetion.net[0].in_features\n",
    "print(output_feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pre-trained parameters\n",
    "load_params = torch.load(os.path.join('/home/hong/dir1/PyTorch-BYOL/runs/Sep26_15-10-29_mango2/checkpoints/model.pth'),\n",
    "                        map_location=torch.device(torch.device(device)))\n",
    "\n",
    "if 'online_network_state_dict' in load_params:\n",
    "    encoder.load_state_dict(load_params['online_network_state_dict'])\n",
    "    print(\"Parameters successfully loaded.\")\n",
    "\n",
    "# remove the projection head\n",
    "encoder = torch.nn.Sequential(*list(encoder.children())[:-1])    \n",
    "encoder = encoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_encoder(encoder, loader):\n",
    "    \n",
    "    x1_train = []\n",
    "    x2_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # get the features from the pre-trained model\n",
    "    # for i, (x1, x2, y) in enumerate(tqdm(loader)):\n",
    "    \n",
    "    for i, (x1, x2, y) in enumerate(tqdm(loader)):\n",
    "        x1=x1.to(device)\n",
    "        x2=x2.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            f_vector1 = encoder(x1)\n",
    "            f_vector2 = encoder(x2)\n",
    "            \n",
    "            f_vector1 = f_vector1.to('cpu')\n",
    "            f_vector2 = f_vector2.to('cpu')\n",
    "    \n",
    "            # x_train.extend(feature_vector)\n",
    "            x1_train.extend(f_vector1)\n",
    "            x2_train.extend(f_vector2)\n",
    "            y_train.extend(y)\n",
    "\n",
    "        # print(x1.shape, x2.shape, feature_vector.shape, y.shape)\n",
    "\n",
    "            \n",
    "    x1_train = torch.stack(x1_train)\n",
    "    x2_train = torch.stack(x2_train)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    return x1_train, x2_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "x1_train, x2_train, y_train = get_features_from_encoder(encoder, train_loader)\n",
    "x1_test, x2_test, y_test = get_features_from_encoder(encoder, test_loader)\n",
    "\n",
    "if len(x1_train.shape) > 2:\n",
    "    print(x1_train.shape)\n",
    "    x1_train = torch.mean(x1_train, dim=[2, 3])\n",
    "    x2_train = torch.mean(x2_train, dim=[2, 3])\n",
    "    x1_test = torch.mean(x1_test, dim=[2, 3])\n",
    "    x2_test = torch.mean(x2_test, dim=[2, 3])\n",
    "    \n",
    "print(\"Training data shape:\", x1_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", x1_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tensor array\n",
    "now = time.localtime()\n",
    "m1 = { 'x1': x1_train, 'x2': x2_train, 'y':y_train}\n",
    "m2 = { 'x1': x1_test, 'x2': x2_test, 'y':y_test}\n",
    "\n",
    "date_dir = \"./tensors/run%02d%02d_%02d%02d/\" % (now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min)\n",
    "os.mkdir(date_dir)\n",
    "train_tensor_path = date_dir+\"train.pt\"\n",
    "test_tensor_path = date_dir+\"test.pt\"\n",
    "torch.save(m1, train_tensor_path)\n",
    "torch.save(m2, test_tensor_path)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4065fc4c518883b19d5c7146216b3edbe965f2c3fa5af4d588617880bfa064c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('october': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
