{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package, module setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sys\n",
    "import yaml\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from torch import cuda\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from mymodels.resnet_base_network import ResNet18\n",
    "from mydata.imageloader import MyDataset, psnrDataUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_transforms = torchvision.transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"../config/config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data, Test data\n",
    "- shuffle the train data\n",
    "- dataset\n",
    "- dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_list = []\n",
    "file_path = \"/home/hong/dir1/PyTorch-BYOL/writing2.txt\"\n",
    "\n",
    "f = open(file_path, 'r')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    listed = line.split(\" \")\n",
    "    tmp_unit = psnrDataUnit(listed[0], listed[1], listed[2], listed[3])\n",
    "    pair_list.append(tmp_unit)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_image_path example:  ('/mnt/URP_DS/HR/124_18.png', '/mnt/URP_DS/HR/68_21.png', 44.17431062)\n",
      "train_image_path example:  ('/mnt/URP_DS/HR/124_18.png', '/mnt/URP_DS/HR/11_23.png', 42.08771409)\n",
      "2029 2029\n"
     ]
    }
   ],
   "source": [
    "train_data_path = '/mnt/URP_DS/HR' # without last slash\n",
    "test_data_path = '/mnt/URP_DS/HR'  #without last slash\n",
    "img1_idx = 0\n",
    "\n",
    "test_imgs_psnr_list = []\n",
    "for p_unit in pair_list:\n",
    "    test_imgs_psnr_list.append((test_data_path+'/'+p_unit.getimg1()+'.png', test_data_path+'/'+p_unit.getimg2()+'.png', p_unit.getsrsum()))\n",
    "\n",
    "# shuffle the pairs for training\n",
    "\n",
    "train_imgs_psnr_list = []\n",
    "for p_unit in pair_list:\n",
    "    train_imgs_psnr_list.append((train_data_path+'/'+p_unit.getimg1()+'.png', train_data_path+'/'+p_unit.getimg2()+'.png', p_unit.getsrsum()))\n",
    "\n",
    "# split train valid from train paths (80,20), (1, 99) -> just for convention\n",
    "set_ratio1 = 0.02\n",
    "set_ratio2 = 1-set_ratio1\n",
    "\n",
    "if set_ratio1<1:\n",
    "    train_imgs_psnr_list, train2_imgs_psnr_list = train_imgs_psnr_list[:int(set_ratio1*len(train_imgs_psnr_list))], train_imgs_psnr_list[int(set_ratio2*len(train_imgs_psnr_list)):]\n",
    "    test_imgs_psnr_list, test2_imgs_psnr_list = test_imgs_psnr_list[:int(set_ratio1*len(test_imgs_psnr_list))], test_imgs_psnr_list[int(set_ratio2*len(test_imgs_psnr_list)):]\n",
    "\n",
    "import random\n",
    "random.shuffle(train_imgs_psnr_list)\n",
    "\n",
    "print('test_image_path example: ', test_imgs_psnr_list[img1_idx])\n",
    "print('train_image_path example: ', train_imgs_psnr_list[img1_idx])\n",
    "print(len(train_imgs_psnr_list), len(test_imgs_psnr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with: cuda\n"
     ]
    }
   ],
   "source": [
    "# device = 'cpu'\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Training with: {device}\")\n",
    "if device=='cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "train_dataset = MyDataset(train_imgs_psnr_list, transform=data_transforms)\n",
    "test_dataset = MyDataset(test_imgs_psnr_list, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input shape:\", train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          num_workers=0, drop_last=False, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                          num_workers=0, drop_last=False, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder loading\n",
    "load encoder for both images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "encoder = ResNet18(**config['network'])\n",
    "output_feature_dim = encoder.projetion.net[0].in_features\n",
    "print(output_feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "#load pre-trained parameters\n",
    "load_params = torch.load(os.path.join('/home/hong/dir1/PyTorch-BYOL/runs/Sep26_15-10-29_mango2/checkpoints/model.pth'),\n",
    "                        map_location=torch.device(torch.device(device)))\n",
    "\n",
    "if 'online_network_state_dict' in load_params:\n",
    "    encoder.load_state_dict(load_params['online_network_state_dict'])\n",
    "    print(\"Parameters successfully loaded.\")\n",
    "\n",
    "# remove the projection head\n",
    "encoder = torch.nn.Sequential(*list(encoder.children())[:-1])    \n",
    "encoder = encoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP setting\n",
    "number of hidden layers: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Class\n",
    "class MyOne(torch.nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, H3, H4, H5, D_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H1)\n",
    "        self.linear2 = torch.nn.Linear(H1, H2)\n",
    "        self.linear3 = torch.nn.Linear(H2, H3)\n",
    "        self.linear4 = torch.nn.Linear(H3, H4)\n",
    "        self.linear5 = torch.nn.Linear(H4, H5)\n",
    "        self.linear6 = torch.nn.Linear(H5, D_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.linear1(x))\n",
    "        x = torch.nn.functional.relu(self.linear2(x))\n",
    "        x = torch.nn.functional.relu(self.linear3(x))\n",
    "        x = torch.nn.functional.relu(self.linear4(x))\n",
    "        x = torch.nn.functional.relu(self.linear5(x))\n",
    "        x = self.linear6(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "linear1.weight \t torch.Size([1024, 1024])\n",
      "linear1.bias \t torch.Size([1024])\n",
      "linear2.weight \t torch.Size([1024, 1024])\n",
      "linear2.bias \t torch.Size([1024])\n",
      "linear3.weight \t torch.Size([1024, 1024])\n",
      "linear3.bias \t torch.Size([1024])\n",
      "linear4.weight \t torch.Size([1024, 1024])\n",
      "linear4.bias \t torch.Size([1024])\n",
      "linear5.weight \t torch.Size([512, 1024])\n",
      "linear5.bias \t torch.Size([512])\n",
      "linear6.weight \t torch.Size([1, 512])\n",
      "linear6.bias \t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# logreg = LogisticRegression(output_feature_dim*2, 10)\n",
    "# logreg = logreg.to(device)\n",
    "mymo = MyOne(output_feature_dim*2, output_feature_dim*2, output_feature_dim*2,output_feature_dim*2, output_feature_dim*2, output_feature_dim, 1)\n",
    "mymo = mymo.to(device)\n",
    "# 모델의 state_dict 출력\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in mymo.state_dict():\n",
    "    print(param_tensor, \"\\t\", mymo.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_encoder(encoder, loader):\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # get the features from the pre-trained model\n",
    "    # for i, (x1, x2, y) in enumerate(tqdm(loader)):\n",
    "    \n",
    "    for i, (x1, x2, y) in enumerate(tqdm(loader)):\n",
    "        x1=x1.to(device)\n",
    "        x2=x2.to(device)\n",
    "        # y=y.to(device)\n",
    "        with torch.no_grad():\n",
    "            f_vector1 = encoder(x1)\n",
    "            f_vector2 = encoder(x2)\n",
    "            feature_vector = torch.cat((f_vector1, f_vector2), 1)\n",
    "            feature_vector=feature_vector.to('cpu')\n",
    "            # y_train=y_train.to('cpu')\n",
    "\n",
    "            x_train.extend(feature_vector)\n",
    "            y_train.extend(y)\n",
    "\n",
    "        # print(x1.shape, x2.shape, feature_vector.shape, y.shape)\n",
    "\n",
    "            \n",
    "    x_train = torch.stack(x_train)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:03<00:00,  1.01it/s]\n",
      "100%|██████████| 64/64 [01:01<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2029, 1024, 10, 10])\n",
      "Training data shape: torch.Size([2029, 1024]) torch.Size([2029])\n",
      "Testing data shape: torch.Size([2029, 1024]) torch.Size([2029])\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "x_train, y_train = get_features_from_encoder(encoder, train_loader)\n",
    "x_test, y_test = get_features_from_encoder(encoder, test_loader)\n",
    "\n",
    "if len(x_train.shape) > 2:\n",
    "    print(x_train.shape)\n",
    "    x_train = torch.mean(x_train, dim=[2, 3])\n",
    "    x_test = torch.mean(x_test, dim=[2, 3])\n",
    "    \n",
    "print(\"Training data shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train).astype(np.float32)\n",
    "x_test = scaler.transform(x_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_data_loaders_from_arrays(torch.from_numpy(x_train), y_train, torch.from_numpy(x_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:23<00:00,  8.43it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(mymo.parameters(), lr=3e-4)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.L1Loss()\n",
    "eval_every_n_epochs = 10\n",
    "first_epoch = 200\n",
    "mymo.train()\n",
    "# device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "# print(f\"Training with: {device}\")\n",
    "for epoch in tqdm(range(first_epoch)):\n",
    "#     train_acc = []\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        logits = mymo(x)\n",
    "        # predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        loss = criterion(logits, y.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    writer.add_scalar(\"Loss/train\", loss, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# second encoding and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:01<00:00,  1.04it/s]\n",
      "100%|██████████| 64/64 [01:01<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2030, 1024, 10, 10])\n",
      "Training data shape: torch.Size([2030, 1024]) torch.Size([2030])\n",
      "Testing data shape: torch.Size([2030, 1024]) torch.Size([2030])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:25<00:00,  7.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(train2_imgs_psnr_list, transform=data_transforms)\n",
    "test_dataset = MyDataset(test2_imgs_psnr_list, transform=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          num_workers=0, drop_last=False, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                          num_workers=0, drop_last=False, shuffle=False, pin_memory=True)\n",
    "\n",
    "encoder.eval()\n",
    "x_train, y_train = get_features_from_encoder(encoder, train_loader)\n",
    "x_test, y_test = get_features_from_encoder(encoder, test_loader)\n",
    "\n",
    "if len(x_train.shape) > 2:\n",
    "    print(x_train.shape)\n",
    "    x_train = torch.mean(x_train, dim=[2, 3])\n",
    "    x_test = torch.mean(x_test, dim=[2, 3])\n",
    "    \n",
    "print(\"Training data shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", x_test.shape, y_test.shape)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train).astype(np.float32)\n",
    "x_test = scaler.transform(x_test).astype(np.float32)\n",
    "\n",
    "train_loader, test_loader = create_data_loaders_from_arrays(torch.from_numpy(x_train), y_train, torch.from_numpy(x_test), y_test)\n",
    "\n",
    "# device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "# print(f\"Training with: {device}\")\n",
    "for epoch in tqdm(range(first_epoch, 2*first_epoch)):\n",
    "#     train_acc = []\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        logits = mymo(x)\n",
    "        # predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        loss = criterion(logits, y.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "################################################################\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2030/2030 [00:00<00:00, 2198.16it/s]\n"
     ]
    }
   ],
   "source": [
    "test_result_diff = []\n",
    "\n",
    "import time\n",
    "now = time.localtime()\n",
    "\n",
    "mymo.eval()\n",
    "for x, y in tqdm(test_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    logits = mymo(x)\n",
    "    ty = 1/float(y[0].item())\n",
    "    oy = 1/logits[0].item()\n",
    "    test_result_diff.append((ty, oy, abs(ty-oy)))\n",
    "\n",
    "with open(\"result_%.2f_%02d%02d_%02d%02d.txt\" %(set_ratio1, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min), 'w') as f:\n",
    "    for item1, item2, item3 in test_result_diff:\n",
    "        f.write(\"sr_sum:%s, model_out:%s, diff(abs):%s\\n\" % (item1, item2, item3))    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4065fc4c518883b19d5c7146216b3edbe965f2c3fa5af4d588617880bfa064c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('october': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
