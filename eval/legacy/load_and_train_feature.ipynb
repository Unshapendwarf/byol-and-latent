{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package, module setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from torch import cuda\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from mymodels.resnet_base_network import ResNet18\n",
    "from mydata.imageloader import MyDataset, psnrDataUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_transforms = torchvision.transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "config = yaml.load(open(\"../config/config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# device = 'cpu'\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Training with: {device}\")\n",
    "if device=='cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-data, Test-data\n",
    "- shuffle the train data\n",
    "- dataset\n",
    "- dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder loading\n",
    "load encoder for both images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ResNet18(**config['network'])\n",
    "output_feature_dim = encoder.projetion.net[0].in_features\n",
    "print(output_feature_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load encoded tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tensor array\n",
    "train_load_path = \"./tensors/runtotal/train.pt\"\n",
    "test_load_path = \"./tensors/runtotal/test.pt\"\n",
    "\n",
    "loaded1 = torch.load(train_load_path)\n",
    "loaded2 = torch.load(test_load_path)\n",
    "\n",
    "x_train = loaded1['x']\n",
    "y_train = loaded1['y']\n",
    "x_test = loaded2['x']\n",
    "y_test = loaded2['y']\n",
    "\n",
    "print(\"Training data shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train).astype(np.float32)\n",
    "x_test = scaler.transform(x_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_data_loaders_from_arrays(torch.from_numpy(x_train), y_train, torch.from_numpy(x_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP setting\n",
    "number of hidden layers: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Class\n",
    "class MyOne(torch.nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, H3, H4, H5, D_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H1)\n",
    "        self.linear2 = torch.nn.Linear(H1, H2)\n",
    "        self.linear3 = torch.nn.Linear(H2, H3)\n",
    "        self.linear4 = torch.nn.Linear(H3, H4)\n",
    "        self.linear5 = torch.nn.Linear(H4, H5)\n",
    "        self.linear6 = torch.nn.Linear(H5, D_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.linear1(x))\n",
    "        x = torch.nn.functional.relu(self.linear2(x))\n",
    "        x = torch.nn.functional.relu(self.linear3(x))\n",
    "        x = torch.nn.functional.relu(self.linear4(x))\n",
    "        x = torch.nn.functional.relu(self.linear5(x))\n",
    "        x = self.linear6(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg = LogisticRegression(output_feature_dim*2, 10)\n",
    "# logreg = logreg.to(device)\n",
    "mymo = MyOne(output_feature_dim*2, output_feature_dim*2, output_feature_dim*2,output_feature_dim*2, output_feature_dim*2, output_feature_dim, 1)\n",
    "mymo = mymo.to(device)\n",
    "# 모델의 state_dict 출력\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in mymo.state_dict():\n",
    "    print(param_tensor, \"\\t\", mymo.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(mymo.parameters(), lr=3e-4)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.L1Loss()\n",
    "eval_every_n_epochs = 10\n",
    "first_epoch = 400\n",
    "mymo.train()\n",
    "# device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "# print(f\"Training with: {device}\")\n",
    "for epoch in tqdm(range(first_epoch)):\n",
    "#     train_acc = []\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        logits = mymo(x)\n",
    "        # predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        loss = criterion(logits, y.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_diff = []\n",
    "\n",
    "now = time.localtime()\n",
    "\n",
    "mymo.eval()\n",
    "for x, y in tqdm(test_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    logits = mymo(x)\n",
    "    ty = 1/float(y[0].item())\n",
    "    oy = 1/logits[0].item()\n",
    "    test_result_diff.append((ty, oy, abs(ty-oy)))\n",
    "\n",
    "with open(\"result_%.2f_%02d%02d_%02d%02d.txt\" %(1.0, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min), 'w') as f:\n",
    "    for item1, item2, item3 in test_result_diff:\n",
    "        f.write(\"sr_sum:%s, model_out:%s, diff(abs):%s\\n\" % (item1, item2, item3))    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4065fc4c518883b19d5c7146216b3edbe965f2c3fa5af4d588617880bfa064c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('october': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
