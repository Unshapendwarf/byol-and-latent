{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import sys\n",
    "import yaml\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from torch import cuda\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from mymodels.resnet_base_network import ResNet18\n",
    "from mydata.imageloader import MyDataset, psnrDataUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_transforms = torchvision.transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"../config/config.yaml\", \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "pair_list = []\n",
    "file_path = \"/home/hong/dir1/PyTorch-BYOL/writing2.txt\"\n",
    "\n",
    "f = open(file_path, 'r')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    listed = line.split(\" \")\n",
    "    tmp_unit = psnrDataUnit(listed[0], listed[1], listed[2], listed[3])\n",
    "    pair_list.append(tmp_unit)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_image_path example:  ('/mnt/URP_DS/HR/93_1.png', '/mnt/URP_DS/HR/106_16.png', 36.082514090000004)\n",
      "test_image_path example:  ('/mnt/URP_DS/HR/124_18.png', '/mnt/URP_DS/HR/68_21.png', 44.17431062)\n",
      "50731 50731\n"
     ]
    }
   ],
   "source": [
    "image_path = '/mnt/URP_DS/HR' # without last slash\n",
    "test_data_path = '/mnt/URP_DS/HR'  #without last slash\n",
    "\n",
    "img1_idx = 0\n",
    "\n",
    "\n",
    "# create the test_image_paths\n",
    "test_imgs_psnr_list = []\n",
    "for p_unit in pair_list:\n",
    "    test_imgs_psnr_list.append((test_data_path+'/'+p_unit.getimg1()+'.png', test_data_path+'/'+p_unit.getimg2()+'.png', p_unit.getonetwo()))\n",
    "\n",
    "# shuffle the pairs for training\n",
    "random.shuffle(pair_list)\n",
    "\n",
    "train_imgs_psnr_list = []\n",
    "for p_unit in pair_list:\n",
    "    train_imgs_psnr_list.append((image_path+'/'+p_unit.getimg1()+'.png', image_path+'/'+p_unit.getimg2()+'.png', p_unit.getonetwo()))\n",
    "# split train valid from train paths (80,20), (1, 99) -> just for convention\n",
    "train_imgs_psnr_list, valid_img_psnr_list = train_imgs_psnr_list[:int(0.5*len(train_imgs_psnr_list))], train_imgs_psnr_list[int(0.5*len(train_imgs_psnr_list)):]\n",
    "test_imgs_psnr_list, valid2_img_psnr_list = test_imgs_psnr_list[:int(0.5*len(test_imgs_psnr_list))], test_imgs_psnr_list[int(0.5*len(test_imgs_psnr_list)):]\n",
    "\n",
    "print('train_image_path example: ', train_imgs_psnr_list[img1_idx])\n",
    "print('test_image_path example: ', test_imgs_psnr_list[img1_idx])\n",
    "print(len(train_imgs_psnr_list), len(test_imgs_psnr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with: cuda\n"
     ]
    }
   ],
   "source": [
    "# device = 'cpu'\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Training with: {device}\")\n",
    "if device=='cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "train_dataset = MyDataset(train_imgs_psnr_list, transform=data_transforms)\n",
    "test_dataset = MyDataset(test_imgs_psnr_list, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input shape:\", train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          num_workers=0, drop_last=False, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                          num_workers=0, drop_last=False, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "encoder = ResNet18(**config['network'])\n",
    "output_feature_dim = encoder.projetion.net[0].in_features\n",
    "print(output_feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "#load pre-trained parameters\n",
    "load_params = torch.load(os.path.join('/home/hong/dir1/PyTorch-BYOL/runs/Sep26_15-10-29_mango2/checkpoints/model.pth'),\n",
    "                        map_location=torch.device(torch.device(device)))\n",
    "\n",
    "if 'online_network_state_dict' in load_params:\n",
    "    encoder.load_state_dict(load_params['online_network_state_dict'])\n",
    "    print(\"Parameters successfully loaded.\")\n",
    "\n",
    "# remove the projection head\n",
    "encoder = torch.nn.Sequential(*list(encoder.children())[:-1])    \n",
    "encoder = encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Class\n",
    "class MyOne(torch.nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, H3, H4, H5, D_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H1)\n",
    "        self.linear2 = torch.nn.Linear(H1, H2)\n",
    "        self.linear3 = torch.nn.Linear(H2, H3)\n",
    "        self.linear4 = torch.nn.Linear(H3, H4)\n",
    "        self.linear5 = torch.nn.Linear(H4, H5)\n",
    "        self.linear6 = torch.nn.Linear(H5, D_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.linear1(x))\n",
    "        x = torch.nn.functional.relu(self.linear2(x))\n",
    "        x = torch.nn.functional.relu(self.linear3(x))\n",
    "        x = torch.nn.functional.relu(self.linear4(x))\n",
    "        x = torch.nn.functional.relu(self.linear5(x))\n",
    "        x = self.linear6(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "linear1.weight \t torch.Size([1024, 1024])\n",
      "linear1.bias \t torch.Size([1024])\n",
      "linear2.weight \t torch.Size([1024, 1024])\n",
      "linear2.bias \t torch.Size([1024])\n",
      "linear3.weight \t torch.Size([1024, 1024])\n",
      "linear3.bias \t torch.Size([1024])\n",
      "linear4.weight \t torch.Size([1024, 1024])\n",
      "linear4.bias \t torch.Size([1024])\n",
      "linear5.weight \t torch.Size([512, 1024])\n",
      "linear5.bias \t torch.Size([512])\n",
      "linear6.weight \t torch.Size([1, 512])\n",
      "linear6.bias \t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# logreg = LogisticRegression(output_feature_dim*2, 10)\n",
    "# logreg = logreg.to(device)\n",
    "mymo = MyOne(output_feature_dim*2, output_feature_dim*2, output_feature_dim*2,output_feature_dim*2, output_feature_dim*2, output_feature_dim, 1)\n",
    "mymo = mymo.to(device)\n",
    "# 모델의 state_dict 출력\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in mymo.state_dict():\n",
    "    print(param_tensor, \"\\t\", mymo.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_encoder(encoder, loader):\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # get the features from the pre-trained model\n",
    "    # for i, (x1, x2, y) in enumerate(tqdm(loader)):\n",
    "    \n",
    "    for i, (x1, x2, y) in enumerate(tqdm(loader)):\n",
    "        x1=x1.to(device)\n",
    "        x2=x2.to(device)\n",
    "        # y=y.to(device)\n",
    "        with torch.no_grad():\n",
    "            f_vector1 = encoder(x1)\n",
    "            f_vector2 = encoder(x2)\n",
    "            feature_vector = torch.cat((f_vector1, f_vector2), 1)\n",
    "            feature_vector=feature_vector.to('cpu')\n",
    "            # y_train=y_train.to('cpu')\n",
    "\n",
    "            x_train.extend(feature_vector)\n",
    "            y_train.extend(y)\n",
    "\n",
    "        # print(x1.shape, x2.shape, feature_vector.shape, y.shape)\n",
    "\n",
    "            \n",
    "    x_train = torch.stack(x_train)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1586/1586 [25:05<00:00,  1.05it/s]\n",
      "100%|██████████| 1586/1586 [24:40<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50731, 1024, 10, 10])\n",
      "Training data shape: torch.Size([50731, 1024]) torch.Size([50731])\n",
      "Testing data shape: torch.Size([50731, 1024]) torch.Size([50731])\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "x_train, y_train = get_features_from_encoder(encoder, train_loader)\n",
    "x_test, y_test = get_features_from_encoder(encoder, test_loader)\n",
    "\n",
    "if len(x_train.shape) > 2:\n",
    "    print(x_train.shape)\n",
    "    x_train = torch.mean(x_train, dim=[2, 3])\n",
    "    x_test = torch.mean(x_test, dim=[2, 3])\n",
    "    \n",
    "print(\"Training data shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train).astype(np.float32)\n",
    "x_test = scaler.transform(x_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_data_loaders_from_arrays(torch.from_numpy(x_train), y_train, torch.from_numpy(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:02<09:19,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013875875156372786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:32<09:43,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010060096392408013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [01:02<08:46,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008444496779702604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [01:32<08:39,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005430689780041575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [02:04<08:28,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006516347639262676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [02:35<07:41,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006446929764933884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [03:04<06:41,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004870874108746648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [03:33<06:06,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003252290771342814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [04:02<05:41,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00032999026007018983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [04:31<05:16,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004168026789557189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [05:00<04:46,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003438391722738743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 111/200 [05:29<04:16,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00029369888943620026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [05:58<03:47,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00028257700614631176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 131/200 [06:26<03:19,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003003411693498492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 141/200 [06:55<02:44,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00026438795612193644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 151/200 [07:24<02:20,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00021617549646180123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 161/200 [07:52<01:51,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016590107406955212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 171/200 [08:21<01:26,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00027700167265720665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 181/200 [08:49<00:53,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00024686832330189645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 191/200 [09:17<00:23,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002486768935341388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [09:44<00:00,  2.92s/it]\n"
     ]
    }
   ],
   "source": [
    "running_loss_history = []\n",
    "running_logit_history = []\n",
    "\n",
    "optimizer = torch.optim.Adam(mymo.parameters(), lr=3e-4)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.L1Loss()\n",
    "eval_every_n_epochs = 10\n",
    "\n",
    "# device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "# print(f\"Training with: {device}\")\n",
    "for epoch in tqdm(range(200)):\n",
    "#     train_acc = []\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        logits = mymo(x)\n",
    "        running_logit_history.append(1/logits[0].item())\n",
    "        # predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        loss = criterion(logits, y.unsqueeze(1))\n",
    "        running_loss_history.append(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % eval_every_n_epochs == 0:\n",
    "        print(loss.item())\n",
    "################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50731/50731 [00:24<00:00, 2099.52it/s]\n"
     ]
    }
   ],
   "source": [
    "test_result_diff = []\n",
    "for x, y in tqdm(test_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    logits = mymo(x)\n",
    "    ty = 1/float(y[0].item())\n",
    "    oy = 1/logits[0].item()\n",
    "    test_result_diff.append((oy, ty, ty-oy))\n",
    "\n",
    "with open('half2_5layer_1029'+'.txt', 'w') as f:\n",
    "    for item1, item2, item3 in test_result_diff:\n",
    "        f.write(\"%s, %s, diff: %s\\n\" % (item1, item2, item3))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4065fc4c518883b19d5c7146216b3edbe965f2c3fa5af4d588617880bfa064c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('october': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
