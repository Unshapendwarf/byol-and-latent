{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package, module setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from torch import cuda\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from mymodels.resnet_base_network import ResNet18\n",
    "from mydata.indexLoader import myDataUnit, nolabel_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "data_transforms = torchvision.transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "config = yaml.load(open(\"../config/config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "# device = 'cpu'\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Training with: {device}\")\n",
    "if device=='cuda':\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# images dataloader\n",
    "- shuffled one\n",
    "- not shuffled one\n",
    "- dataset\n",
    "- dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "curr_psnr_sum = 30\n",
    "# file_path = \"./image_name_less\" + str(curr_psnr_sum)+ \".txt\"\n",
    "# encoder_out_dir = str(curr_psnr_sum)+\"db\"\n",
    "\n",
    "# file_path = \"./image_names_all\"+ \".txt\"\n",
    "# encoder_out_dir = \"all\"\n",
    "\n",
    "\n",
    "file_path = \"final_names.txt\"\n",
    "encoder_out_dir = \"final\"\n",
    "\n",
    "f = open(file_path, 'r')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    listed = line.split(\" \")\n",
    "    image_list.append(listed[0].strip())\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_int(imgname):\n",
    "    lhs, rhs = imgname.split(\"_\")\n",
    "    strint = int(lhs)*1000 + int(rhs)\n",
    "    return int(strint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_n_name example:  ('/home/hong/dir1/final_eval/HR/10_10.png', 10010)\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/hong/dir1/final_eval/HR' # without last slash\n",
    "\n",
    "path_n_name = []\n",
    "for img_name in image_list:\n",
    "    path_n_name.append( tuple((data_path+'/'+img_name+'.png', name_to_int(img_name))) )\n",
    "\n",
    "# shuffle the pairs for training\n",
    "# import random\n",
    "# random.shuffle(path_n_name)\n",
    "\n",
    "print('path_n_name example: ', path_n_name[0])\n",
    "print(len(path_n_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = nolabel_dataset(path_n_name, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input shape:\", my_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataloader = DataLoader(my_dataset, batch_size=batch_size,\n",
    "                          num_workers=0, drop_last=False, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder loading\n",
    "load encoder for both images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "encoder = ResNet18(**config['network'])\n",
    "output_feature_dim = encoder.projetion.net[0].in_features\n",
    "print(output_feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "#load pre-trained parameters, BYOL pretrained model\n",
    "load_params = torch.load(os.path.join('../runs/0118_run/checkpoints/model.pth'),\n",
    "                        map_location=torch.device(torch.device(device)))\n",
    "\n",
    "if 'online_network_state_dict' in load_params:\n",
    "    encoder.load_state_dict(load_params['online_network_state_dict'])\n",
    "    print(\"Parameters successfully loaded.\")\n",
    "\n",
    "# remove the projection head\n",
    "encoder = torch.nn.Sequential(*list(encoder.children())[:-1])    \n",
    "encoder = encoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_encoder(encoder, loader):\n",
    "    \n",
    "    x1_train = []\n",
    "    y_train = []\n",
    "    for x1, y in tqdm(loader):\n",
    "        x1=x1.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            f_vector1 = encoder(x1)\n",
    "            f_vector1 = f_vector1.to('cpu')\n",
    "            x1_train.extend(f_vector1)\n",
    "            y_train.extend(y)\n",
    "\n",
    "    x1_train = torch.stack(x1_train)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    \n",
    "    return x1_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:20<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 512, 10, 10])\n",
      "Training data shape: torch.Size([1000, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "x1, y = get_features_from_encoder(encoder, my_dataloader)\n",
    "\n",
    "if len(x1.shape) > 2:\n",
    "    print(x1.shape)\n",
    "    x1 = torch.mean(x1, dim=[2, 3])\n",
    "    \n",
    "print(\"Training data shape:\", x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tensor array\n",
    "m1 = { 'x1': x1, 'y' : y}\n",
    "\n",
    "date_dir = \"./tensors/%s/byol_encoder_out/\" % (encoder_out_dir)\n",
    "if os.path.exists(date_dir) == False:\n",
    "    os.mkdir(date_dir)\n",
    "tensor_path = date_dir+\"x2.pt\"  ## os.path.join()\n",
    "torch.save(m1, tensor_path)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4065fc4c518883b19d5c7146216b3edbe965f2c3fa5af4d588617880bfa064c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('october': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
